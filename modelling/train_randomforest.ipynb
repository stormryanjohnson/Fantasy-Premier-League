{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from helper import *\n",
    "import mlflow\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "training_set = pd.read_csv('../data/model_dataset/training_set.csv', index_col='unique_id')\n",
    "test_set = pd.read_csv('../data/model_dataset/test_set.csv', index_col='unique_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and target while dropping unwanted columns\n",
    "X_train = training_set.drop(columns=['target_value', 'Unnamed: 0', 'full_name'])\n",
    "y_train = training_set['target_value']\n",
    "\n",
    "X_test = test_set.drop(columns=['target_value', 'Unnamed: 0', 'full_name'])\n",
    "y_test = test_set['target_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/03 23:50:05 INFO mlflow.tracking.fluent: Experiment with name 'RandomForest' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Duration 1241 s\n"
     ]
    }
   ],
   "source": [
    "experiment_start = time.time()\n",
    "\n",
    "mlflow.set_tracking_uri(\"../mlruns\")\n",
    "mlflow.set_experiment('RandomForest')\n",
    "\n",
    "n_estimators_range = [1000]\n",
    "max_depth_range = [2, 10, 15, 20, 40, 50]\n",
    "min_samples_split_range = [2, 5, 10, 20]\n",
    "min_samples_leaf_range = [1, 2, 5, 10, 20]\n",
    "max_features_range = [1, 'auto', 'sqrt', 'log2']\n",
    "random_state = 42\n",
    "\n",
    "features = str(list(X_train.columns))\n",
    "count = 0\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_depth in max_depth_range:\n",
    "        for min_samples_split in min_samples_split_range:\n",
    "            for min_samples_leaf in min_samples_leaf_range:\n",
    "                for max_features in max_features_range:\n",
    "                    with mlflow.start_run():\n",
    "                        count += 1\n",
    "                        #print(\"######################### Iteration Nr: {} ##############################\".format(count))\n",
    "                        scoring = ['neg_mean_absolute_error', 'r2', 'neg_mean_squared_error']\n",
    "                        \n",
    "                        # log hyperparameters\n",
    "                        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "                        mlflow.log_param(\"max_depth\", max_depth)\n",
    "                        mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "                        mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
    "                        mlflow.log_param(\"max_features\", max_features)\n",
    "                        mlflow.log_param(\"features\", features)\n",
    "\n",
    "                        # scoring = ['neg_mean_absolute_error', 'neg_root_mean_squared_error', 'r2']\n",
    "\n",
    "                        # define model using hyperparameters\n",
    "                        rf_parameters = {\"n_estimators\": n_estimators,\n",
    "                                        \"max_depth\": max_depth,\n",
    "                                        \"min_samples_split\": min_samples_split,\n",
    "                                        \"min_samples_leaf\": min_samples_leaf,\n",
    "                                        \"max_features\": max_features,\n",
    "                                        \"random_state\": random_state}\n",
    "\n",
    "                        rf_model = RandomForestRegressor(**rf_parameters)\n",
    "\n",
    "                        # define cross-validation method to use\n",
    "                        scores = cross_validate(estimator=rf_model, X=X_train, y=y_train,\n",
    "                                                scoring=scoring, cv=5, n_jobs=-1)\n",
    "                        \n",
    "                        # create new model to evaluate test set scores\n",
    "                        rf_model = RandomForestRegressor(**rf_parameters)\n",
    "                        rf_model.fit(X=X_train, y=y_train)\n",
    "                        y_pred = pd.Series(rf_model.predict(X_test))\n",
    "                        # round the targets to the nearest 5 \n",
    "                        y_pred = y_pred.apply(round_to_nearest_5)\n",
    "                        \n",
    "                        # obtain and log metrics\n",
    "                        r2 = scores[\"test_r2\"].mean()\n",
    "                        mse = -1.0 * (scores[\"test_neg_mean_squared_error\"].mean())\n",
    "                        mae = -1.0 * (scores[\"test_neg_mean_absolute_error\"].mean())\n",
    "\n",
    "                        r2_holdout = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "                        mse_holdout = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "                        mae_holdout = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
    "                        \n",
    "                        mlflow.log_metric(\"R2\", r2)\n",
    "                        mlflow.log_metric(\"MSE\", mse)\n",
    "                        mlflow.log_metric(\"MAE\", mae)\n",
    "                        mlflow.log_metric(\"R2_holdout\", r2_holdout)\n",
    "                        mlflow.log_metric(\"MSE_holdout\", mse_holdout)\n",
    "                        mlflow.log_metric(\"MAE_holdout\", mae_holdout)\n",
    "\n",
    "print(\"Experiment Duration {} s\".format(str(round((time.time() - experiment_start)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set and test final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.7599956520951466\n",
      "MSE:  39.130434782608695\n",
      "MAE:  3.9130434782608696\n",
      "     Predicted  Actual\n",
      "0         45.0    45.0\n",
      "1         45.0    45.0\n",
      "2         50.0    50.0\n",
      "3         45.0    50.0\n",
      "4        105.0    90.0\n",
      "..         ...     ...\n",
      "179       60.0    65.0\n",
      "180       50.0    55.0\n",
      "181       45.0    50.0\n",
      "182       85.0    80.0\n",
      "183       50.0    50.0\n",
      "\n",
      "[184 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "rf_final_parameters = {   \n",
    "                \"n_estimators\": 1000,\n",
    "                \"max_depth\": 20,\n",
    "                \"min_samples_split\": 20,\n",
    "                \"min_samples_leaf\": 2,\n",
    "                \"max_features\": 'auto',\n",
    "                \"random_state\": 42\n",
    "                }\n",
    "\n",
    "rf_final_model = RandomForestRegressor(**rf_final_parameters)\n",
    "\n",
    "rf_final_model.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = pd.Series(rf_final_model.predict(X_test))\n",
    "# round the targets to the nearest 5 \n",
    "y_pred = y_pred.apply(round_to_nearest_5)\n",
    "\n",
    "pred = pd.DataFrame(data=y_pred, columns=['Predicted'])\n",
    "actual = pd.DataFrame(data=y_test.values, columns=['Actual'])\n",
    "\n",
    "results = pd.concat([pred, actual], axis=1)\n",
    "print('R2: ', r2_score(y_true=y_test, y_pred=y_pred))\n",
    "print('MSE: ', mean_squared_error(y_true=y_test, y_pred=y_pred))\n",
    "print('MAE: ', mean_absolute_error(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/rf_v0.0.1.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_final_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from the pickle file\n",
    "with open('../models/rf_v0.0.1.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
